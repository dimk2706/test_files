import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import uuid
import json
import random
import os
import time
import asyncio
from dotenv import load_dotenv
import boto3
from botocore.config import Config
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env
load_dotenv()

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
OBS_ACCESS_KEY = os.getenv("OBS_ACCESS_KEY")
OBS_SECRET_KEY = os.getenv("OBS_SECRET_KEY")
OBS_REGION = os.getenv("OBS_REGION")
OBS_ENDPOINT = os.getenv("OBS_ENDPOINT")
OBS_BUCKET = os.getenv("OBS_BUCKET")

required_vars = {
    "OBS_ACCESS_KEY": OBS_ACCESS_KEY,
    "OBS_SECRET_KEY": OBS_SECRET_KEY,
    "OBS_REGION": OBS_REGION,
    "OBS_ENDPOINT": OBS_ENDPOINT,
    "OBS_BUCKET": OBS_BUCKET,
}

for name, value in required_vars.items():
    if not value:
        raise EnvironmentError(f"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è {name} –Ω–µ –∑–∞–¥–∞–Ω–∞")


def create_excel_with_retry(df, filename, max_retries=3):
    """–°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
    for attempt in range(max_retries):
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_filename = f"temp_{filename}"
            
            wb = Workbook()
            ws = wb.active
            ws.title = "Sheet1"
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            headers = list(df.columns)
            ws.append(headers)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            for _, row in df.iterrows():
                ws.append(row.tolist())
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫
            widths = {
                'A': 20, 'B': 30, 'C': 12, 'D': 8, 'E': 8,
                'F': 20, 'G': 15, 'H': 18, 'I': 15, 'J': 10, 'K': 50
            }
            
            for col, width in widths.items():
                ws.column_dimensions[col].width = width
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            wb.save(temp_filename)
            
            # –Ø–≤–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º workbook
            del wb
            
            # –î–∞–µ–º –≤—Ä–µ–º—è —Å–∏—Å—Ç–µ–º–µ –∑–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª
            time.sleep(0.5)
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –∫–æ–Ω–µ—á–Ω—ã–π
            if os.path.exists(filename):
                os.remove(filename)
            os.rename(temp_filename, filename)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä
            file_size = os.path.getsize(filename)
            if file_size > 0:
                print(f"‚úÖ Excel —Å–æ–∑–¥–∞–Ω: {filename} ({file_size} –±–∞–π—Ç)")
                return True
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª —Å–æ–∑–¥–∞–Ω –Ω–æ –∏–º–µ–µ—Ç –Ω—É–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Excel (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ –æ—à–∏–±–∫–µ
            for temp_file in [filename, f"temp_{filename}"]:
                if os.path.exists(temp_file):
                    try:
                        os.remove(temp_file)
                    except:
                        pass
            time.sleep(1)  # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
    
    return False


def upload_to_cloud_sync(filepath: str):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –≤ S3-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ –æ–±–ª–∞–∫–æ"""
    if not os.path.exists(filepath):
        print(f"‚ùå –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {filepath}")
        return False
        
    file_size = os.path.getsize(filepath)
    if file_size == 0:
        print(f"‚ùå –§–∞–π–ª –ø—É—Å—Ç–æ–π: {filepath}")
        return False
        
    print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª: {filepath} ({file_size} –±–∞–π—Ç)")

    object_name = os.path.basename(filepath)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º Content-Type
    if filepath.lower().endswith('.xlsx'):
        content_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    elif filepath.lower().endswith('.parquet'):
        content_type = 'application/octet-stream'
    else:
        content_type = 'application/octet-stream'

    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
    session = boto3.session.Session()
    config = Config(s3={'addressing_style': 'virtual'})

    client = session.client(
        's3',
        region_name=OBS_REGION,
        endpoint_url=OBS_ENDPOINT,
        aws_access_key_id=OBS_ACCESS_KEY,
        aws_secret_access_key=OBS_SECRET_KEY,
        config=config
    )

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º upload_file –≤–º–µ—Å—Ç–æ put_object
        client.upload_file(
            filepath,
            OBS_BUCKET,
            object_name,
            ExtraArgs={'ContentType': content_type}
        )
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {object_name}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filepath}: {e}")
        return False


def generate_random_data(num_rows=10):
    symbols = ['CNY/RUB', 'USD/RUB', 'EUR/RUB', 'GBP/RUB', 'JPY/RUB']
    states = [0, 1]
    tenors = ['TOM', 'SPOT', 'TOD', 'ON']
    tiers = ['TRADER1', 'TRADER2', 'TRADER3', 'TRADER4', 'TRADER5']
    
    data = []
    for _ in range(num_rows):
        time = datetime.now() - timedelta(days=random.randint(0, 30),
                                         hours=random.randint(0, 23),
                                         minutes=random.randint(0, 59))
        ulid = str(uuid.uuid4())[:24].upper()
        symbol = random.choice(symbols)
        state = random.choice(states)
        tenor = random.choice(tenors)
        value_date_near = time + timedelta(days=random.randint(1, 5))
        global_tradable = random.choice([0, 1])
        global_indicative = 1 - global_tradable
        rate_id = random.randint(10000000000, 99999999999)
        tier = random.choice(tiers)
        bid_price = random.randint(8000000, 12000000)
        ask_price = bid_price + random.randint(100000, 500000)
        size = random.randint(100000, 5000000)
        price_levels = {
            'bid': {'price': str(bid_price), 'size': str(size)},
            'ask': {'price': str(ask_price), 'size': str(size)}
        }
        data.append({
            'time': time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            'ulid': ulid,
            'symbol': symbol,
            'state': state,
            'tenor': tenor,
            'valueDateNear': value_date_near.strftime('%Y-%m-%dT%H:%M:%SZ'),
            'globalTradable': global_tradable,
            'globalIndicative': global_indicative,
            'rateId': rate_id,
            'tier': tier,
            'priceLevels': json.dumps(price_levels)
        })
    return data


def get_next_file_number(base_name="Book1", extension="xlsx"):
    today = datetime.now().strftime("%Y-%m-%d")
    pattern = f"{base_name}_{today}_"
    existing_files = [f for f in os.listdir('.') if f.startswith(pattern) and f.endswith(f".{extension}")]
    if not existing_files:
        return 1
    numbers = []
    for file in existing_files:
        try:
            num_part = file.replace(f"{pattern}", "").replace(f".{extension}", "")
            numbers.append(int(num_part))
        except ValueError:
            continue
    return max(numbers) + 1 if numbers else 1


def create_data_files_sync(num_rows=10):
    """–°–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª—ã —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (Excel/Parquet), –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º–µ–Ω–∞"""
    file_number = get_next_file_number()
    today = datetime.now().strftime("%Y-%m-%d")
    
    data = generate_random_data(num_rows)
    df = pd.DataFrame(data)
    df.columns = ['time', 'ulid', 'symbol', 'state', 'tenor', 'valueDateNear',
                  'globalTradable', 'globalIndicative', 'rateId', 'tier', 'priceLevels']
    
    excel_filename = f"Book1_{today}_{file_number}.xlsx"
    parquet_filename = f"database_{today}_{file_number}.parquet"
    
    # –°–æ–∑–¥–∞–µ–º Excel —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
    if not create_excel_with_retry(df, excel_filename):
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Excel —Ñ–∞–π–ª –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫")
        return None, None, None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ Excel –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ
    try:
        test_df = pd.read_excel(excel_filename, engine='openpyxl')
        print(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ Excel: {len(test_df)} —Å—Ç—Ä–æ–∫")
    except Exception as e:
        print(f"‚ùå –õ–æ–∫–∞–ª—å–Ω—ã–π Excel —Ñ–∞–π–ª –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è: {e}")
        return None, None, None
    
    # Parquet
    try:
        df.to_parquet(parquet_filename, index=False, engine='pyarrow')
        parquet_size = os.path.getsize(parquet_filename)
        print(f"‚úÖ Parquet —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {parquet_filename} ({parquet_size} –±–∞–π—Ç)")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Parquet: {e}")
        return None, None, None
    
    return excel_filename, parquet_filename, df


def create_consolidated_database_sync():
    parquet_files = [f for f in os.listdir('.') if f.startswith('database_') and f.endswith('.parquet')]
    if not parquet_files:
        print("‚ùå –ù–µ—Ç Parquet-—Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏")
        return None
    all_dfs = []
    for f in parquet_files:
        try:
            df = pd.read_parquet(f)
            df['source_file'] = f
            all_dfs.append(df)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {f}: {e}")
    if not all_dfs:
        return None
    consolidated = pd.concat(all_dfs, ignore_index=True)
    cons_filename = f"consolidated_database_{datetime.now().strftime('%Y-%m-%d')}.parquet"
    consolidated.to_parquet(cons_filename, index=False)
    print(f"‚úÖ –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ë–î: {cons_filename}")
    return cons_filename


async def main():
    print("üöÄ –ù–∞—á–∞–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
    
    # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    excel_file, parquet_file, df = create_data_files_sync(num_rows=150)
    
    if not excel_file or not parquet_file:
        print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤")
        return
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –æ–±–ª–∞–∫–æ
    print("‚òÅÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ –æ–±–ª–∞–∫–æ...")
    upload_to_cloud_sync(excel_file)
    upload_to_cloud_sync(parquet_file)
    
    print("\n" + "="*60)
    
    # 3. –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞
    print("üîÑ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    consolidated_file = create_consolidated_database_sync()
    if consolidated_file:
        print("‚òÅÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ë–î...")
        upload_to_cloud_sync(consolidated_file)
    
    print("\n‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω!")


# --- –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    asyncio.run(main())